\chapter{Fazit}
\label{ch:fazit}
Alles in allem konnten in dieser Arbeit die Ergebnisse von Pawara et al. \cite{pawaraPaper} bestätigt werden.
Durch die vielen Kombinationen an Parametern für das Training wurden der OvO und OvA Ansatz unter verschiedensten Bedingungen untersucht und miteinander verglichen.

Dabei ist die Verwendung eines OvO Klassifikationsschemas besonders bei Trainingsdurchläufen \textit{from Scratch}, also mit zufällig initialisierten Gewichten, und wenigen Trainingsbeispielen vielversprechend und kann sowohl zu einem stabileren Trainingsverlauf als auch zu besseren Ergebnissen beitragen.

Darüber hinaus gestaltet sich die Implementation eines OvO Klassifikationsschemas vergleichsweise einfach (s. Kapitel \ref{ch:methodik}). Somit ist es bei dem Training von tiefen neuronalen Netzen \textit{from Scratch} eindeutig ratsam, das OvO Klassifikationsschema anzuwenden bzw. zu untersuchen, ob der OvO Ansatz bei der konkreten Problemstellung von Vorteil ist. Besonders wenn das Training mit wenigen Trainingsdaten durchgeführt werden muss, bringt das OvO Klassifikationsschema in fast allen Fällen eine Verbesserung der Ergebnisse im Vergleich zu dem standardmäßig verwendeten OvA Ansatz (s. Kapitel \ref{ch:diskussionOvOvsOvA}) mit sich. Die Wahl des Klassifikationsschemas kann also als ein weiterer möglicher Hyperparameter für das Training tiefer neuronaler Netze verstanden werden.\\\\

Leider musste in dieser Arbeit aber auch festgestellt werden, dass die Wahl des Frameworks erheblichen Einfluss auf die Qualität der Ergebnisse haben kann. So schneidet TensorFlow 2.4.1 \cite{tensorflow} im Vergleich zu den anderen beiden Frameworks eher schlecht ab. Nur dort treten unerklärliche Ausreißer nach unten und sehr instabile Trainingsverläufe auf. Es wirkt so, als wäre TensorFlow \cite{tensorflow} von Version 1.13.1 zu Version 2.4.1 zumindest bei den in dieser Arbeit durchgeführten Experimenten tatsächlich schlechter geworden.

PyTorch \cite{pytorch} hingegen scheint eine sehr gute Wahl zu sein, da die Ergebnisse auf einem vergleichbar guten Niveau wie bei TensorFlow 1.13.1 \cite{tensorflow} liegen, während die Trainingsdauer bedingt durch die bessere Auslastung der Grafikkarte größtenteils wesentlich kürzer ist als die von TensorFlow \cite{tensorflow} (s. Kapitel \ref{ch:diskussionFrameworks}).\\\\

\newpage

Weitere spannende Untersuchungen für die Zukunft könnten sich ergeben, wenn der OvO Ansatz auf komplett anderen Datensätzen untersucht wird. In dieser Arbeit, wie auch im Paper von Pawara et al. \cite{pawaraPaper}, wurden größtenteils Datensätze mit Bildern aus der Natur wie z.B. Bilder von Blättern, Früchten und Affen verwendet. Außerdem wäre es interessant zu untersuchen, ab welcher Klassenanzahl der Mehraufwand für das Training so stark angewachsen ist, dass der OvO Ansatz sich in dieser Form nicht mehr als praktikabel erweist.\\\\

Darüber hinaus kann an den in dieser Arbeit und im Paper von Pawara et al. \cite{pawaraPaper} verwendeten Hyperparametern gearbeitet werden. So zeigt sich besonders am Verlauf des Trainings (s. Abb. \ref{fig:TrainingsverlaufA}, \ref{fig:TrainingsverlaufB} und \ref{fig:TrainingsverlaufC}), dass immer in den Epochen nach einer Anpassung der Learning-Rate eine starke Veränderung sowohl bei den Loss- als auch Accuracy-Werten hervorgerufen wird. Eventuell wäre es ein guter Ansatz die Learning-Rate nicht sprunghaft alle 50 Epochen zu verringern, sondern sie während des Trainings kontinuierlich zu senken. Außerdem könnte die initiale Learning-Rate variiert werden, da die größten Fortschritte bei dem Training meistens nicht innerhalb der ersten 50 Epochen stattfinden (s. Kapitel \ref{ch:Beispiele}).\\\\

Eine weitere Möglichkeit für zukünftige Untersuchungen wäre es, wie Pawara et al. auch schon vorgeschlagen haben (vgl. \cite{pawaraPaper}, 6. Conclusion), bei Finetune Experimenten für faire Bedingungen zwischen den beiden Klassifikationsschemata zu sorgen, indem die auf ImageNet \cite{imagenet} vor-trainierten Gewichte mit dem jeweils passenden Klassifikationsschema erzeugt werden, sodass Finetuning Experimente mit dem OvO Ansatz auch vor-trainierte initiale Gewichte bekommen, die mit dem OvO Klassifikationsschema vor-trainiert wurden.
